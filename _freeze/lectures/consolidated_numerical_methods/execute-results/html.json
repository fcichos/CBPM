{
  "hash": "d630bde2a97d3777308d19697a701430",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nformat:\n  live-html:\n    toc: true\n    toc-location: right\npyodide:\n  autorun: false\n  packages:\n    - matplotlib\n    - numpy\n    - scipy\n---\n\n# Numerical Methods for Differential Equations in Physics\n\n## Introduction\n\nDifferential equations form the mathematical backbone of physics, describing how physical quantities change in relation to one another. Whether we're calculating velocity from position, acceleration from velocity, electric fields, wave propagation, or quantum systems, we're working with derivatives and their associated differential equations. This document provides a comprehensive approach to numerical solutions for differential equations, starting with numerical differentiation methods and advancing to solving ordinary differential equations (ODEs).\n\n```{pyodide}\n#| edit: false\n#| echo: false\n#| execute: true\n\nimport numpy as np\nimport io\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.sparse import diags\nfrom scipy.integrate import solve_ivp\n\n# default values for plotting\nplt.rcParams.update({\n                     'font.size': 12,\n                     'text.usetex': False,\n                     'font.family': 'serif',\n                     'axes.labelsize': 12,\n                     'axes.titlesize': 12,\n                     'xtick.labelsize': 10,\n                     'ytick.labelsize': 10,\n                     'legend.fontsize': 10,\n                     'figure.titlesize': 12,\n                     'xtick.major.size': 3,\n                     'ytick.major.size': 3,\n                     'xtick.major.width': 0.5,\n                     'ytick.major.width': 0.5,\n                     'axes.linewidth': 0.5,\n                     'grid.linewidth': 0.5,\n                     'lines.linewidth': 1.5,\n                     'xtick.direction' : 'in',\n                     'ytick.direction' : 'in',})\n\ndef get_size(w,h):\n      return((w/2.54,h/2.54))\n      \ndef set_plot_style():\n    plt.style.use('seaborn-v0_8-whitegrid')\n    plt.rcParams.update({\n        'figure.figsize': (10, 6),\n        'axes.grid': True,\n        'grid.linestyle': '--',\n        'grid.alpha': 0.7,\n        'lines.linewidth': 2,\n        'font.size': 12,\n        'axes.labelsize': 14,\n        'axes.titlesize': p16,\n        'xtick.labelsize': 12,\n        'ytick.labelsize': 12\n    })\n```\n\n## Part 1: Numerical Differentiation\n\n### The Calculus Foundations\n\nBefore diving into numerical methods, let's revisit the calculus definition of a derivative. The derivative of a function $f(x)$ at a point $x$ is defined as the limit of the difference quotient as the interval $\\Delta x$ approaches zero:\n\n$$\nf^{\\prime}(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}\n$$\n\nThis definition captures the instantaneous rate of change of $f$ with respect to $x$. In physics, derivatives represent essential physical quantities:\n\n- The derivative of position with respect to time is velocity\n- The derivative of velocity with respect to time is acceleration\n- The derivative of potential energy with respect to position gives force\n\nHowever, in computational physics, we cannot take the limit to zero as computers work with discrete values. Instead, we approximate the derivative using finite differences. This is also possible for higher order derivatives, which can be approximated using more complex finite difference formulas such as\n\n$$\nf^{(n)}(x)=\\lim _{\\Delta x  \\rightarrow 0} \\frac{1}{\\Delta x ^n} \\sum_{k=0}^n(-1)^{k+n}\\binom{n}{k} f(x+k \\Delta x )\n$$\n\n### Finite Difference Approximations\n\nNumerical differentiation methods primarily rely on finite difference approximations derived from Taylor series expansions. Let's explore these systematically.\n\n#### Forward Difference\n\nThe simplest approximation is the forward difference method. It approximates the derivative using the current point and the next point:\n\n$$\nf'(x) \\approx \\frac{f(x + \\Delta x) - f(x)}{\\Delta x} + O(\\Delta x)\n$$\n\nWhere $O(\\Delta x)$ represents the error term, indicating that the error decreases linearly with the step size.\n\n#### Central Difference\n\nThe central difference method uses points on both sides of the current point to approximate the derivative:\n\n$$\nf'(x) \\approx \\frac{f(x + \\Delta x) - f(x - \\Delta x)}{2\\Delta x} + O(\\Delta x^2)\n$$\n\nThis method has a higher order of accuracy – the error decreases quadratically with the step size.\n\n#### Higher-Order Approximations\n\nFor applications requiring higher accuracy, we can derive higher-order approximations:\n\n$$\nf'(x) \\approx \\frac{-f(x + 2\\Delta x) + 8f(x + \\Delta x) - 8f(x - \\Delta x) + f(x - 2\\Delta x)}{12\\Delta x} + O(\\Delta x^4)\n$$\n\n### Implementation in Python\n\nLet's implement these methods and compare their accuracies using a known function:\n\n```{pyodide}\n#| autorun: false\n\ndef f(x):\n    return np.sin(x)\n\ndef f_prime_exact(x):\n    return np.cos(x)\n\ndef forward_diff(f, x, h):\n    return (f(x + h) - f(x)) / h\n\ndef central_diff(f, x, h):\n    return (f(x + h) - f(x - h)) / (2 * h)\n\ndef higher_order_diff(f, x, h):\n    return (-f(x + 2*h) + 8*f(x + h) - 8*f(x - h) + f(x - 2*h)) / (12 * h)\n\n# Test point\nx0 = np.pi/4\nexact_derivative = f_prime_exact(x0)\n\n# Test different step sizes\nh_values = np.logspace(-1, -10, 10)\nforward_errors = []\ncentral_errors = []\nhigher_errors = []\n\nfor h in h_values:\n    forward_errors.append(abs(forward_diff(f, x0, h) - exact_derivative))\n    central_errors.append(abs(central_diff(f, x0, h) - exact_derivative))\n    higher_errors.append(abs(higher_order_diff(f, x0, h) - exact_derivative))\n\nplt.figure(figsize=get_size(10, 8))\nplt.loglog(h_values, forward_errors, 'o-', label='Forward Difference')\nplt.loglog(h_values, central_errors, 's-', label='Central Difference')\nplt.loglog(h_values, higher_errors, '^-', label='Higher-Order')\nplt.loglog(h_values, h_values, '--', label='O(h)')\nplt.loglog(h_values, np.power(h_values, 2), ':', label='O(h²)')\nplt.loglog(h_values, np.power(h_values, 4), '-.', label='O(h⁴)')\nplt.xlabel('Step Size (h)')\nplt.ylabel('Absolute Error')\nplt.title('Error in Derivative Approximations')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n#### Error Analysis\n\nThe plot demonstrates how each method's error behaves as the step size decreases. Initially, the error decreases at the expected rate based on the order of the method. However, for very small step sizes, roundoff errors begin to dominate due to the limitations of floating-point arithmetic.\n\n### Matrix Representation of Derivatives\n\nFor many physical problems, we need to compute derivatives over an entire spatial or temporal domain. In these cases, we can represent differentiation operations as matrix operations.\n\n#### First Derivative Matrix\n\nFor a first derivative on a uniform grid with $n$ points, the central difference approximation can be represented as:\n\n$$\nD_1 = \\frac{1}{2\\Delta x}\n\\begin{pmatrix}\n0 & 1 & 0 & \\cdots & 0 \\\\\n-1 & 0 & 1 & \\cdots & 0 \\\\\n0 & -1 & 0 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 0\n\\end{pmatrix}\n$$\n\n#### Second Derivative Matrix\n\nSimilarly, the second derivative can be represented as:\n\n$$\nD_2 = \\frac{1}{\\Delta x^2}\n\\begin{pmatrix}\n-2 & 1 & 0 & \\cdots & 0 \\\\\n1 & -2 & 1 & \\cdots & 0 \\\\\n0 & 1 & -2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & -2\n\\end{pmatrix}\n$$\n\n```{pyodide}\n#| autorun: false\n\ndef create_derivative_matrix(n, dx, order=1):\n    \"\"\"\n    Create a finite difference matrix for derivatives.\n    \n    Parameters:\n    n (int): Number of grid points\n    dx (float): Grid spacing\n    order (int): Order of derivative (1 or 2)\n    \n    Returns:\n    scipy.sparse.dia_matrix: Sparse matrix for the derivative\n    \"\"\"\n    if order == 1:\n        # First derivative (central difference)\n        diagonals = [np.ones(n-1), np.zeros(n), -np.ones(n-1)]\n        offsets = [1, 0, -1]\n        D = diags(diagonals, offsets, shape=(n, n)) / (2*dx)\n    elif order == 2:\n        # Second derivative\n        diagonals = [np.ones(n-1), -2*np.ones(n), np.ones(n-1)]\n        offsets = [1, 0, -1]\n        D = diags(diagonals, offsets, shape=(n, n)) / (dx**2)\n    else:\n        raise ValueError(\"Only first and second order derivatives are supported\")\n    \n    return D\n\n# Example usage\nx = np.linspace(0, 2*np.pi, 100)\ndx = x[1] - x[0]\ny = np.sin(x)\n\n# Create derivative matrices\nD1 = create_derivative_matrix(len(x), dx, order=1)\nD2 = create_derivative_matrix(len(x), dx, order=2)\n\n# Compute derivatives\ny_prime = D1.dot(y)\ny_double_prime = D2.dot(y)\n\n# Plot results\nplt.figure(figsize=get_size(12, 8))\n\nplt.subplot(311)\nplt.plot(x, y, label='sin(x)')\nplt.title('Function')\nplt.legend()\n\nplt.subplot(312)\nplt.plot(x, y_prime, label='Numerical')\nplt.plot(x, np.cos(x), '--', label='Analytical')\nplt.title('First Derivative')\nplt.legend()\n\nplt.subplot(313)\nplt.plot(x, y_double_prime, label='Numerical')\nplt.plot(x, -np.sin(x), '--', label='Analytical')\nplt.title('Second Derivative')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n### Boundary Conditions\n\nIn physical problems, we often need to specify boundary conditions for our derivatives. Common types include:\n\n- **Dirichlet conditions**: Specify the function values at boundaries\n- **Neumann conditions**: Specify the derivative values at boundaries\n- **Periodic conditions**: The function values and derivatives match at opposite boundaries\n\nThe choice of boundary conditions affects how we construct our derivative matrices, especially at the edges of the domain.\n\n## Part 2: Solving Ordinary Differential Equations\n\nNow that we understand numerical differentiation, we can apply these techniques to solve ordinary differential equations (ODEs), which are ubiquitous in physics.\n\n### The Harmonic Oscillator\n\nLet's start with a classic physical system: the harmonic oscillator. The equation of motion is:\n\n$$\n\\frac{d^2x}{dt^2} + \\omega^2 x = 0\n$$\n\nwhere $\\omega$ is the angular frequency of the oscillator. \n\n::: {.callout-note}\nThis is a second order differential equation which requires two initial conditions for its solution: the initial elongation $x(t=0)=x_{0}$ and the initial velocity $\\dot{x}(t=0)=v_{0}$.\n:::\n\n### Implicit Matrix Solution\n\nUsing the matrix representation of the second derivative that we developed earlier, we can transform the ODE into a system of linear equations that can be solved implicitly.\n\n#### Define Matrices\n\nOur matrix will consist of two parts. The first containing the second derivative and the second just the elongation. Suppose we want to calculate the position $x(t)$ at 6 instances in time $t_{i}$, then the matrix version of the second derivative reads as:\n\n$T=\\frac{d^2x}{dt^2}=\\frac{1}{\\delta t^2}\n\\begin{bmatrix}\n-2 & 1  & 0 & 0 & 0 & 0\\\\\n 1 & -2 & 1 & 0 & 0 & 0\\\\\n 0 & 1  & -2 & 1 & 0 & 0\\\\\n 0 & 0  & 1  & -2 & 1 & 0\\\\\n 0 & 0  & 0  &  1 & -2 & 1\\\\\n 0 & 0  & 0  &  0 &  1 & -2\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}$\n\nThe second term in the equation of motion can be represented as:\n\n$V=\\omega^2 x=\\begin{bmatrix}\n\\omega^2  & 0  & 0 & 0 & 0 & 0\\\\\n 0 & \\omega^2  & 0 & 0 & 0 & 0\\\\\n 0 & 0  & \\omega^2  & 0 & 0 & 0\\\\\n 0 & 0  & 0  & \\omega^2  & 0 & 0\\\\\n 0 & 0  & 0  &  0 & \\omega^2  & 0\\\\\n 0 & 0  & 0  &  0 &  0 & \\omega^2\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}$\n\nThe equation of motion can then be written as $T \\cdot x + V \\cdot x = 0$, or $(T + V) \\cdot x = 0$.\n\n#### Implementation\n\n```{pyodide}\n#| autorun: false\n\n# Define parameters\nn_points = 100  # Number of time points\nt_max = 10.0     # Maximum time\ndt = t_max / (n_points - 1)  # Time step\nomega = 2.0      # Angular frequency\nx0 = 1.0         # Initial position\nv0 = 0.0         # Initial velocity\n\n# Create time array\nt = np.linspace(0, t_max, n_points)\n\n# Create the second derivative matrix\ndiagonals = [np.ones(n_points-1), -2*np.ones(n_points), np.ones(n_points-1)]\noffsets = [1, 0, -1]\nD2 = diags(diagonals, offsets, shape=(n_points, n_points)) / (dt**2)\n\n# Create the potential matrix (just omega^2 on the diagonal)\nV = diags([omega**2 * np.ones(n_points)], [0])\n\n# Combine matrices\nM = D2 + V\n\n# Incorporate boundary conditions\n# We know x(0) = x0 and (dx/dt)(0) = v0\n# For first-order boundary condition (velocity), we use the forward difference\nM[0, :] = 0\nM[0, 0] = 1  # x(0) = x0\n\n# For second-order boundary condition (acceleration), we use the numerical second derivative\nM[1, 0:3] = np.array([1, -2, 1]) / (dt**2)\n\n# Create the right-hand side vector\nb = np.zeros(n_points)\nb[0] = x0  # Initial position\nb[1] = -omega**2 * x0  # Initial acceleration from the ODE\n\n# Solve the system\nx = np.linalg.solve(M, b)\n\n# Plot the solution\nplt.figure(figsize=get_size(10, 7))\nplt.plot(t, x, label='Numerical Solution')\nplt.plot(t, x0*np.cos(omega*t), '--', label='Analytical Solution')\nplt.xlabel('Time (s)')\nplt.ylabel('Position x(t)')\nplt.title('Harmonic Oscillator Solution')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n### Explicit Solution Methods\n\nInstead of solving the entire system implicitly, we can use step-by-step numerical integration methods. These methods are particularly useful for non-linear ODEs.\n\n#### Converting to First-Order System\n\nWe can convert any second-order ODE to a system of first-order ODEs by introducing additional variables. For the harmonic oscillator:\n\n$$\n\\frac{d^2x}{dt^2} + \\omega^2 x = 0\n$$\n\nWe introduce $v = \\frac{dx}{dt}$ and rewrite as:\n\n$$\n\\begin{align}\n\\frac{dx}{dt} &= v \\\\\n\\frac{dv}{dt} &= -\\omega^2 x\n\\end{align}\n$$\n\n#### Euler Method\n\nThe simplest numerical integration method is the Euler method:\n\n$$\n\\begin{align}\nx_{n+1} &= x_n + v_n \\Delta t \\\\\nv_{n+1} &= v_n - \\omega^2 x_n \\Delta t\n\\end{align}\n$$\n\n```{pyodide}\n#| autorun: false\n\ndef euler_method(f, y0, t_span, dt):\n    \"\"\"\n    Implements the Euler method for solving ODEs.\n    \n    Parameters:\n    f: Function that returns the derivative dy/dt = f(t, y)\n    y0: Initial condition\n    t_span: (t_start, t_end)\n    dt: Time step\n    \n    Returns:\n    t: Array of time points\n    y: Array of solution values\n    \"\"\"\n    t_start, t_end = t_span\n    n_steps = int((t_end - t_start) / dt) + 1\n    t = np.linspace(t_start, t_end, n_steps)\n    y = np.zeros((n_steps, len(y0)))\n    y[0] = y0\n    \n    for i in range(1, n_steps):\n        y[i] = y[i-1] + dt * f(t[i-1], y[i-1])\n    \n    return t, y\n```\n\n#### Euler-Cromer Method\n\nThe Euler-Cromer method is more stable for oscillatory systems:\n\n$$\n\\begin{align}\nv_{n+1} &= v_n - \\omega^2 x_n \\Delta t \\\\\nx_{n+1} &= x_n + v_{n+1} \\Delta t\n\\end{align}\n$$\n\n```{pyodide}\n#| autorun: false\n\ndef euler_cromer_method(f, y0, t_span, dt):\n    \"\"\"\n    Implements the Euler-Cromer method for solving oscillatory ODEs.\n    \n    Parameters:\n    f: Function that returns the derivative dy/dt = f(t, y)\n    y0: Initial condition [position, velocity]\n    t_span: (t_start, t_end)\n    dt: Time step\n    \n    Returns:\n    t: Array of time points\n    y: Array of solution values [position, velocity]\n    \"\"\"\n    t_start, t_end = t_span\n    n_steps = int((t_end - t_start) / dt) + 1\n    t = np.linspace(t_start, t_end, n_steps)\n    y = np.zeros((n_steps, len(y0)))\n    y[0] = y0\n    \n    for i in range(1, n_steps):\n        # Update velocity first\n        derivatives = f(t[i-1], y[i-1])\n        y[i, 1] = y[i-1, 1] + dt * derivatives[1]\n        # Then update position using new velocity\n        y[i, 0] = y[i-1, 0] + dt * y[i, 1]\n    \n    return t, y\n```\n\n#### Midpoint Method\n\nThe midpoint method has better accuracy:\n\n$$\n\\begin{align}\nk_1 &= f(t_n, y_n) \\\\\nk_2 &= f(t_n + \\frac{\\Delta t}{2}, y_n + \\frac{\\Delta t}{2}k_1) \\\\\ny_{n+1} &= y_n + \\Delta t \\cdot k_2\n\\end{align}\n$$\n\n```{pyodide}\n#| autorun: false\n\ndef midpoint_method(f, y0, t_span, dt):\n    \"\"\"\n    Implements the midpoint method for solving ODEs.\n    \n    Parameters:\n    f: Function that returns the derivative dy/dt = f(t, y)\n    y0: Initial condition\n    t_span: (t_start, t_end)\n    dt: Time step\n    \n    Returns:\n    t: Array of time points\n    y: Array of solution values\n    \"\"\"\n    t_start, t_end = t_span\n    n_steps = int((t_end - t_start) / dt) + 1\n    t = np.linspace(t_start, t_end, n_steps)\n    y = np.zeros((n_steps, len(y0)))\n    y[0] = y0\n    \n    for i in range(1, n_steps):\n        k1 = f(t[i-1], y[i-1])\n        k2 = f(t[i-1] + dt/2, y[i-1] + dt/2 * k1)\n        y[i] = y[i-1] + dt * k2\n    \n    return t, y\n```\n\n#### Comparison of Methods\n\nLet's compare these methods for the harmonic oscillator:\n\n```{pyodide}\n#| autorun: false\n\n# Define the harmonic oscillator system\ndef harmonic_oscillator(t, y, omega=2.0):\n    \"\"\"\n    Harmonic oscillator as a system of first-order ODEs.\n    y[0] is position, y[1] is velocity.\n    \"\"\"\n    dydt = np.zeros_like(y)\n    dydt[0] = y[1]\n    dydt[1] = -omega**2 * y[0]\n    return dydt\n\n# Initial conditions\ny0 = np.array([1.0, 0.0])  # [position, velocity]\nt_span = (0, 20)\ndt = 0.1\nomega = 2.0\n\n# Analytical solution\ndef analytical_solution(t, x0=1.0, v0=0.0, omega=2.0):\n    return x0 * np.cos(omega * t) + v0/omega * np.sin(omega * t)\n\n# Solve using different methods\nt_euler, y_euler = euler_method(lambda t, y: harmonic_oscillator(t, y, omega), y0, t_span, dt)\nt_cromer, y_cromer = euler_cromer_method(lambda t, y: harmonic_oscillator(t, y, omega), y0, t_span, dt)\nt_midpoint, y_midpoint = midpoint_method(lambda t, y: harmonic_oscillator(t, y, omega), y0, t_span, dt)\n\n# Compute analytical solution\ny_analytical = analytical_solution(t_euler, y0[0], y0[1], omega)\n\n# Plot comparison\nplt.figure(figsize=get_size(12, 10))\n\nplt.subplot(2, 1, 1)\nplt.plot(t_euler, y_euler[:, 0], label='Euler')\nplt.plot(t_cromer, y_cromer[:, 0], label='Euler-Cromer')\nplt.plot(t_midpoint, y_midpoint[:, 0], label='Midpoint')\nplt.plot(t_euler, y_analytical, '--', label='Analytical')\nplt.xlabel('Time (s)')\nplt.ylabel('Position x(t)')\nplt.title('Comparison of Numerical Methods for Harmonic Oscillator')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(t_euler, np.abs(y_euler[:, 0] - y_analytical), label='Euler Error')\nplt.plot(t_cromer, np.abs(y_cromer[:, 0] - y_analytical), label='Euler-Cromer Error')\nplt.plot(t_midpoint, np.abs(y_midpoint[:, 0] - y_analytical), label='Midpoint Error')\nplt.yscale('log')\nplt.xlabel('Time (s)')\nplt.ylabel('Absolute Error')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n### Solving ODEs with SciPy\n\nFor practical applications, the SciPy library provides sophisticated ODE solvers:\n\n```{pyodide}\n#| autorun: false\n\n# Define the ODE system\ndef SHO(t, y, omega=2.0):\n    \"\"\"Simple Harmonic Oscillator\"\"\"\n    x, v = y\n    dxdt = v\n    dvdt = -omega**2 * x\n    return [dxdt, dvdt]\n\n# Parameters\nt_span = (0, 20)\ny0 = [1.0, 0.0]  # Initial [position, velocity]\nomega = 2.0\n\n# Solve using scipy.integrate.solve_ivp\nsolution = solve_ivp(\n    lambda t, y: SHO(t, y, omega),\n    t_span,\n    y0,\n    method='RK45',\n    t_eval=np.linspace(t_span[0], t_span[1], 500)\n)\n\n# Plot solution\nplt.figure(figsize=get_size(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(solution.t, solution.y[0], label='Position')\nplt.plot(solution.t, solution.y[1], label='Velocity')\nplt.plot(solution.t, analytical_solution(solution.t, y0[0], y0[1], omega), '--', label='Analytical')\nplt.xlabel('Time (s)')\nplt.ylabel('Value')\nplt.title('Simple Harmonic Oscillator using SciPy')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(solution.y[0], solution.y[1])\nplt.xlabel('Position')\nplt.ylabel('Velocity')\nplt.title('Phase Space Trajectory')\nplt.axis('equal')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n```\n\n## Advanced Example: Damped Driven Pendulum\n\nLet's apply our knowledge to a more complex system: a damped driven pendulum. The equation of motion is:\n\n$$\n\\frac{d^2\\theta}{dt^2} + b\\frac{d\\theta}{dt} + \\omega_0^2\\sin\\theta = F_0\\cos(\\omega_d t)\n$$\n\nwhere $\\theta$ is the angle, $b$ is the damping coefficient, $\\omega_0$ is the natural frequency, $F_0$ is the driving amplitude, and $\\omega_d$ is the driving frequency.\n\n```{pyodide}\n#| autorun: false\n\ndef damped_driven_pendulum(t, y, b=0.1, omega0=1.0, F0=0.5, omega_d=0.7):\n    \"\"\"\n    Damped driven pendulum ODE system.\n    y[0] is theta (angle), y[1] is omega (angular velocity).\n    \"\"\"\n    theta, omega = y\n    dtheta_dt = omega\n    domega_dt = -b*omega - omega0**2 * np.sin(theta) + F0 * np.cos(omega_d * t)\n    return [dtheta_dt, domega_dt]\n\n# Parameters\nt_span = (0, 50)\ny0 = [0.1, 0.0]  # Initial [angle, angular velocity]\nb = 0.1          # Damping coefficient\nomega0 = 1.0     # Natural frequency\nF0 = 0.5         # Driving amplitude\nomega_d = 0.7    # Driving frequency\n\n# Solve using scipy.integrate.solve_ivp\nsolution = solve_ivp(\n    lambda t, y: damped_driven_pendulum(t, y, b, omega0, F0, omega_d),\n    t_span,\n    y0,\n    method='RK45',\n    t_eval=np.linspace(t_span[0], t_span[1], 1000)\n)\n\n# Plot solution\nplt.figure(figsize=get_size(12, 10))\n\nplt.subplot(2, 1, 1)\nplt.plot(solution.t, solution.y[0], label='Angle')\nplt.plot(solution.t, solution.y[1], label='Angular Velocity')\nplt.xlabel('Time (s)')\nplt.ylabel('Value')\nplt.title('Damped Driven Pendulum')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(solution.y[0], solution.y[1])\nplt.xlabel('Angle')\nplt.ylabel('Angular Velocity')\nplt.title('Phase Space Trajectory')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n```\n\n## Conclusion\n\nIn this comprehensive exploration, we've covered numerical methods for differentiation and integration, and applied them to solve ordinary differential equations. We've progressed from basic concepts to advanced applications, providing a solid foundation for numerical methods in physics.\n\nThe matrix-based approach is particularly powerful for linear problems, while explicit integration methods are versatile for a wide range of ODEs. For complex problems, SciPy's ODE solvers provide robust and efficient solutions.\n\n## What to Try Yourself\n\n1. Implement higher-order Runge-Kutta methods and compare their accuracy\n2. Solve a coupled oscillator system (two or more oscillators connected by springs)\n3. Explore chaotic behavior in the damped driven pendulum by varying parameters\n4. Implement adaptive step size methods for improved efficiency\n5. Apply these methods to specific physics problems in your area of interest\n\n## Further Reading\n\n- Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (2007). Numerical Recipes: The Art of Scientific Computing (3rd ed.). Cambridge University Press.\n- Burden, R. L., & Faires, J. D. (2015). Numerical Analysis (10th ed.). Cengage Learning.\n- Hairer, E., Nørsett, S. P., & Wanner, G. (2008). Solving Ordinary Differential Equations I: Nonstiff Problems. Springer.\n- LeVeque, R. J. (2007). Finite Difference Methods for Ordinary and Partial Differential Equations: Steady-State and Time-Dependent Problems. SIAM.\n- Landau, R. H., Páez, M. J., & Bordeianu, C. C. (2015). Computational Physics: Problem Solving with Python (3rd ed.). Wiley-VCH.\n- Newman, M. (2012). Computational Physics. CreateSpace Independent Publishing Platform.\n\n",
    "supporting": [
      "consolidated_numerical_methods_files"
    ],
    "filters": [],
    "includes": {}
  }
}