{
  "hash": "65433e6bed63eefff120803d40fa93e1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nformat:\n  live-html:\n    toc: true\n    toc-location: right\npyodide:\n  autorun: false\n  packages:\n    - matplotlib\n    - numpy\n    - scipy\n---\n\n## Dealing with text files containing data\n\nIn physics laboratory experiments, you'll frequently encounter the need to handle data stored in text files. Whether you're collecting measurements from a pendulum experiment, analyzing spectrometer readings, or processing particle collision data, efficiently importing, manipulating, and exporting this data is essential for your analysis. As second-semester physics students, mastering these file handling techniques will save you significant time when processing experimental results and allow you to focus on the physical interpretation rather than data management. This section covers the fundamental approaches to working with data files in Python, from basic file operations to specialized tools in NumPy that are particularly useful for the large datasets common in physics applications.\n\n### Input using Python's File Handling\n\nTo input or output data to a file you can use Python's built-in file handling, e.g. to write data:\n\n```{pyodide}\nimport numpy as np\n\n# Create sample data\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([10, 20, 30, 40, 50])\n\n# Write data to file using Python's file handling\nwith open('data.txt', 'w') as file:\n    for x_val, y_val in zip(x, y):\n        file.write(f\"{x_val}, {y_val}\\n\")\n\nprint(\"Data written to file using Python's file handling\")\n```\n\nThis approach gives you more control over formatting and is useful when dealing with complex data structures or when you need custom formatting. Python's built-in file handling allows you to precisely control how each line is formatted, which is particularly valuable when working with heterogeneous data or when you need to create files that conform to specific format requirements.\n\n\n:::{.callout-note collapse=true}\nThe Python `with` statement is a context manager that provides a clean and efficient way to handle resources that need setup and teardown operations, such as file handling, database connections, or network connections.\n\nThe basic syntax looks like this:\n\n```python\nwith expression as variable:\n    # code block\n```\n\nThe `with` statement ensures that resources are properly managed by automatically handling the setup before entering the code block and the cleanup after exiting it, even if exceptions occur within the block.\n\nHere's a common example with file operations:\n\n```python\nwith open('file.txt', 'r') as file:\n    data = file.read()\n    # Process data\n# File is automatically closed when exiting the with block\n```\n\nThe key benefits of using the `with` statement include:\n\n1. Automatic resource management - no need to explicitly call methods like `close()`\n2. Exception safety - resources are properly cleaned up even if exceptions occur\n3. Cleaner, more readable code compared to try-finally blocks\n\nIn physics and electrical engineering contexts, you might use the `with` statement when working with measurement equipment, data acquisition, or when processing large datasets that require temporary file handling.\n:::\n\n### Text Data Input and Output with NumPy\n\nNumPy provides several functions for reading and writing text data, which can be particularly useful for handling numeric data stored in text files.\n\n#### Loading Text Data with NumPy\n\n##### Using `np.loadtxt`\n\nThe most common method for loading text data is `np.loadtxt`. This function reads data from a text file and creates a NumPy array with the values:\n\n```{pyodide}\nimport numpy as np\n\n# Load data from a text file\ndata = np.loadtxt('data.txt', delimiter=',')  # Add delimiter to parse the comma-separated values\nprint(f\"Loaded data shape: {data.shape}\")\nprint(data)  # Display the loaded data to confirm it matches what was written\n```\n\nYou can customize how `loadtxt` interprets the file using various parameters. For instance, you can specify a delimiter to handle CSV files, skip header rows that contain metadata, and select only specific columns to read:\n\n```python\n# Load with specific delimiter, skipping rows, and selecting columns\ndata = np.loadtxt('data.txt',\n                  delimiter=',',   # CSV file\n                  skiprows=1,      # Skip header row\n                  usecols=(0, 1, 2))  # Use only first three columns\n```\n\n##### Using `np.genfromtxt`\n\nFor more flexible loading, especially with missing values, NumPy provides the `genfromtxt` function. This function is particularly useful when dealing with real-world data that may have inconsistencies or missing entries:\n\n```python\n# Handle missing values with genfromtxt\ndata = np.genfromtxt('data_with_missing.txt',\n                     delimiter=',',\n                     filling_values=-999,  # Replace missing values\n                     skip_header=1)        # Skip header row\n```\n\nThe `genfromtxt` function allows you to specify how missing values should be handled, making it more robust for imperfect datasets where some entries might be missing or corrupted.\n\n#### Saving Text Data with NumPy\n\n##### Using `np.savetxt`\n\nYou can save NumPy arrays to text files using the `savetxt` function. This function allows you to convert your array data into a human-readable text format that can be easily shared or used by other programs:\n\n```{pyodide}\n# Create some data\nx = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Save to CSV file\nnp.savetxt('output.csv', x, delimiter=',', fmt='%d')\n```\n\nThe `savetxt` function offers numerous formatting options to control exactly how your data is written. You can add headers and footers to provide context, specify the numeric format of your data, and control other aspects of the output file:\n\n```{pyodide}\n# Save with header and footer\nnp.savetxt('output_formatted.csv', x,\n           delimiter=',',\n           header='col1,col2,col3',  # Column header\n           footer='End of data',\n           fmt='%.2f',               # Format as float with 2 decimal places\n           comments='# ')            # Change comment character\n```\n\nThese formatting options give you considerable control over how your numerical data is presented in the output file, which can be important for compatibility with other software or for human readability.\n\n#### Example Workflow\n\nHere's a complete example of reading, processing, and writing text data that demonstrates a typical data analysis workflow using NumPy's I/O capabilities:\n\n```{pyodide}\nimport numpy as np\n\n# Read data\ndata = np.loadtxt('input.csv', delimiter=',', skiprows=1)\n\n# Process data (calculate statistics)\nrow_means = np.mean(data, axis=1)\nrow_maxes = np.max(data, axis=1)\nrow_mins = np.min(data, axis=1)\n\n# Combine original data with calculated statistics\nresult = np.column_stack((data, row_means, row_maxes, row_mins))\n\n# Save processed data\nheader = \"val1,val2,val3,mean,max,min\"\nnp.savetxt('processed_data.csv', result,\n           delimiter=',',\n           header=header,\n           fmt='%.3f')\n\nprint(\"Data processing complete!\")\n```\n\nThis workflow demonstrates how NumPy can efficiently handle text-based data input and output for numerical analysis. The example reads data from a CSV file, performs statistical calculations on each row, combines the original data with the calculated statistics, and then saves the processed results to a new CSV file with appropriate headers. This type of pipeline is common in data analysis and scientific computing, where raw data is imported, transformed, and then exported in a more useful format.\n\n",
    "supporting": [
      "0_input_output_files"
    ],
    "filters": [],
    "includes": {}
  }
}