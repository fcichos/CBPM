{
  "hash": "20515346511fea3cbe9747a64f9e0f6d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nformat:\n  live-html:\n    page-layout: full\n    toc: true\n    toc-location: right\npyodide:\n  autorun: false\n  packages:\n    - matplotlib\n    - numpy\n    - scipy\n---\n\n## Introduction to Numerical Integration in Physics\n\nNumerical integration stands as one of the fundamental computational tools in physics, enabling us to solve problems where analytical solutions are either impossible or impractical. In physics, we frequently encounter integrals when calculating quantities such as:\n\n- Work done by a variable force\n- Electric and magnetic fields from complex charge distributions\n- Center of mass of irregularly shaped objects\n- Probability distributions in quantum mechanics\n- Energy levels in quantum wells with arbitrary potentials\n- Heat flow in non-uniform materials\n\nThe need for numerical integration arises because many physical systems are described by functions that cannot be integrated analytically. For example, the potential energy of a complex molecular system, the trajectory of a spacecraft under multiple gravitational influences, or the behavior of quantum particles in complex potentials.\n\nIn this lecture, we'll explore three progressively more accurate numerical integration methods: the Box method, Trapezoid method, and Simpson's method. We'll analyze their accuracy, efficiency, and appropriate applications in physical problems.\n\n```{pyodide}\n#| edit: false\n#| echo: false\n#| execute: true\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\n# Set default plotting parameters\nplt.rcParams.update({\n    'font.size': 12,\n    'lines.linewidth': 1,\n    'lines.markersize': 5,\n    'axes.labelsize': 11,\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'xtick.top': True,\n    'xtick.direction': 'in',\n    'ytick.right': True,\n    'ytick.direction': 'in',\n})\n\ndef get_size(w, h):\n    return (w/2.54, h/2.54)\n```\n\n### Box Method (Rectangle Method)\n\n#### Theory and Implementation\n\n![Box Method Illustration](img/box.png){#fig-box}\n\nThe Box method (also known as the Rectangle method) represents the simplest approach for numerical integration. It approximates the function in each interval $\\Delta x$ with a constant value taken at a specific point of the interval—typically the left endpoint, although midpoint or right endpoint variants exist.\n\nMathematically, the definite integral is approximated as:\n\n\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^{N} f(x_{i}) \\Delta x\n\\end{equation}\n\nWhere:\n\n- $a$ and $b$ are the integration limits\n- $N$ is the number of intervals\n- $\\Delta x = \\frac{b-a}{N}$ is the width of each interval\n- $x_i$ represents the left endpoint of each interval\n\nThe method gets its name from the visual representation of the approximation as a series of rectangular boxes.\n\n#### Box Method Applications\n\n::: {.panel-tabset}\n### Physics Application: Work Calculation\n\nConsider a particle moving along a straight line under a variable force $F(x) = kx^2$ where $k$ is some constant. The work done by this force when moving the particle from position $x=0$ to $x=L$ is given by:\n\n\\begin{equation}\nW = \\int_{0}^{L} F(x) dx = \\int_{0}^{L} kx^2 dx\n\\end{equation}\n\nWe can approximate this integral using the Box method, particularly useful when the force follows a complex pattern measured at discrete points.\n\n```{pyodide}\ndef f(x):\n    \"\"\"Example function to integrate: f(x) = x\"\"\"\n    return x\n\ndef force(x, k=1.0):\n    \"\"\"Force function F(x) = kx^2 for work calculation\"\"\"\n    return k * x**2\n\ndef int_box(f, a, b, N):\n    \"\"\"Box method integration\"\"\"\n    if N < 2:\n        raise ValueError(\"N must be at least 2\")\n    x = np.linspace(a, b, N)\n    y = f(x)\n    dx = (b-a)/(N-1)\n    return np.sum(y[:-1] * dx)  # Sum using left endpoints\n\n# Example: Calculate work done by a nonlinear force\nL = 2.0  # meters\nk = 0.5  # N/m^3\nN_points = 100\n\nwork = int_box(lambda x: force(x, k), 0, L, N_points)\nprint(f\"Work done by force F(x) = {k}x² from x=0 to x={L} m:\")\nprint(f\"Numerical result (Box method): {work:.6f} J\")\nprint(f\"Analytical result: {k*L**3/3:.6f} J\")\n\n# Demonstrate the method graphically\nx_demo = np.linspace(0, 1, 6)\ny_demo = x_demo  # Using f(x) = x for demonstration\ndx_demo = x_demo[1] - x_demo[0]\n\nplt.figure(figsize=get_size(15, 10))\n\n# Plot the actual function\nx_fine = np.linspace(0, 1, 1000)\ny_fine = x_fine\nplt.plot(x_fine, y_fine, 'b-', label='actual function f(x) = x')\n\n# Plot the boxes\nfor i in range(len(x_demo)-1):\n    plt.fill_between([x_demo[i], x_demo[i+1]], [y_demo[i], y_demo[i]], alpha=0.3, color='red')\n    plt.plot([x_demo[i], x_demo[i]], [0, y_demo[i]], 'r--', alpha=0.5)\n\nplt.plot(x_demo[:-1], y_demo[:-1], 'ro', label='Sample points')\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n```\n\n### Convergence Analysis\n\n```{pyodide}\n# Convergence demonstration\nN_values = np.arange(10, 10000, 100)\nbox_results = [int_box(f, 0, 1, N) for N in N_values]\nexact_value = 0.5  # Exact integral of f(x) = x from 0 to 1\n\n# Calculate absolute errors\nbox_errors = np.abs(np.array(box_results) - exact_value)\n\n# Fit a power law to error vs N\ndef power_law(x, a, b):\n    return a * x**b\n\npopt, _ = curve_fit(power_law, N_values, box_errors)\n\nplt.figure(figsize=get_size(15, 10))\nplt.loglog(N_values, box_errors, 'o', label='Box Method Error')\nplt.loglog(N_values, power_law(N_values, *popt), '--',\n         label=f'Power Law Fit: error ∝ N^{popt[1]:.2f}')\nplt.xlabel('number of points [N]')\nplt.ylabel('absolute Error')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nprint(f\"Box Method convergence rate: approximately O(N^{popt[1]:.2f})\")\n```\n\n:::\n\n### Trapezoid Method\n\n#### Theory and Implementation\n\n![Trapezoid Method Illustration](img/trapez.png){#fig-trap}\n\nThe Trapezoid method improves upon the Box method by approximating the function with linear segments between consecutive points. Instead of using constant values within each interval, it connects adjacent points with straight lines, forming trapezoids.\n\nThe mathematical formula for the Trapezoid method is:\n\n\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^{N-1} \\frac{f(x_i) + f(x_{i+1})}{2} \\Delta x\n\\end{equation}\n\nWhere:\n- $\\Delta x = \\frac{b-a}{N-1}$ is the width of each interval\n- $x_i$ are the sample points\n\nThis method is particularly effective for smoothly varying functions, which are common in physical systems.\n\n#### Trapezoid Application\n\n::: {.panel-tabset}\n### Physics Application: Electric Potential from Charge Distribution\n\nA practical application in electromagnetism involves calculating the electric potential at a point due to a non-uniform charge distribution along a line. For a linear charge density $\\lambda(x)$ along the x-axis, the potential at point $(0,d)$ is given by:\n\n\\begin{equation}\nV(0,d) = \\frac{1}{4\\pi\\epsilon_0} \\int_{a}^{b} \\frac{\\lambda(x)}{\\sqrt{x^2 + d^2}} dx\n\\end{equation}\n\nThe Trapezoid method is well-suited for this calculation, especially when $\\lambda(x)$ is provided as experimental data points.\n\n```{pyodide}\ndef int_trap(f, a, b, N):\n    \"\"\"Trapezoid method integration\"\"\"\n    if N < 2:\n        raise ValueError(\"N must be at least 2\")\n    x = np.linspace(a, b, N)\n    y = f(x)\n    dx = (b-a)/(N-1)\n    return np.sum((y[1:] + y[:-1]) * dx/2)\n\n# Simple demonstration\ndef f_demo(x):\n    return x**2  # Using f(x) = x² for demonstration\n\n# Demonstrate the trapezoid method visually\nx_demo = np.linspace(0, 1, 6)\ny_demo = f_demo(x_demo)\n\nplt.figure(figsize=get_size(15, 8))\n# Plot the actual function\nx_fine = np.linspace(0, 1, 1000)\ny_fine = f_demo(x_fine)\nplt.plot(x_fine, y_fine, 'b-', label='actual function f(x) = x²')\n\n# Plot the trapezoids\nfor i in range(len(x_demo)-1):\n    plt.fill_between([x_demo[i], x_demo[i+1]],\n                    [y_demo[i], y_demo[i+1]],\n                    alpha=0.3, color='green')\n    plt.plot([x_demo[i], x_demo[i+1]], [y_demo[i], y_demo[i+1]], 'g-')\n\nplt.plot(x_demo, y_demo, 'go', label='sample points')\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.tight_layout()\nplt.legend()\nplt.show()\n\n```\n\n\n### Convergence Analysis\n```{pyodide}\n\n# Convergence demonstration\nN_values = np.arange(10, 1000, 10)\ntrap_results = [int_trap(f_demo, 0, 1, N) for N in N_values]\nexact_value = 1/3  # Exact integral of x² from 0 to 1\n\n# Calculate absolute errors\ntrap_errors = np.abs(np.array(trap_results) - exact_value)\n\n# Fit a power law to error vs N\ndef power_law(x, a, b):\n    return a * x**b\n\npopt, _ = curve_fit(power_law, N_values, trap_errors)\n\nplt.figure(figsize=get_size(12, 10))\nplt.loglog(N_values, trap_errors, 'o', label='trapezoid method error')\nplt.loglog(N_values, power_law(N_values, *popt), '--',\n         label=f'power law fit: error ∝ N^{popt[1]:.2f}')\nplt.xlabel('number of points [N]')\nplt.ylabel('absolute error')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nprint(f\"Trapezoid Method convergence rate: approximately O(N^{popt[1]:.2f})\")\n```\n:::\n\n\n### Simpson's Method\n\n#### Theory and Implementation\n\n![Simpson's Method Illustration](img/simpson.png){#fig-simp}\n\nSimpson's method represents a significant improvement in accuracy over the previous methods by approximating the function with parabolic segments rather than straight lines. This approach is particularly effective for functions with curvature, which are ubiquitous in physics problems.\n\nThe mathematical formulation of Simpson's rule is:\n\n\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\frac{\\Delta x}{3} \\sum_{i=0}^{(N-1)/2} \\left(f(x_{2i}) + 4f(x_{2i+1}) + f(x_{2i+2})\\right)\n\\end{equation}\n\nWhere:\n- $N$ is the number of intervals (must be even)\n- $\\Delta x = \\frac{b-a}{N}$ is the width of each interval\n\nSimpson's rule is derived from fitting a quadratic polynomial through every three consecutive points and then integrating these polynomials.\n\n\n#### Simpson's Nethod Applications\n\n::: {.panel-tabset}\n### Physics Application: Quantum Mechanical Probability\n\nA fundamental application in quantum mechanics involves calculating the probability of finding a particle in a region of space. For a wavefunction $\\psi(x)$, the probability of finding the particle between positions $a$ and $b$ is:\n\n\\begin{equation}\nP(a \\leq x \\leq b) = \\int_{a}^{b} |\\psi(x)|^2 dx\n\\end{equation}\n\nSimpson's method provides high accuracy for these calculations, especially important when dealing with oscillatory wavefunctions.\n\n```{pyodide}\ndef int_simp(f, a, b, N):\n    \"\"\"Simpson's method integration\"\"\"\n    if N % 2 == 0:\n        N = N + 1  # Ensure N is odd for Simpson's rule\n\n    if N < 3:\n        raise ValueError(\"N must be at least 3 for Simpson's method\")\n\n    x = np.linspace(a, b, N)\n    y = f(x)\n    dx = (b-a)/(N-1)\n\n    # Apply Simpson's formula\n    return dx/3 * np.sum(y[0:-2:2] + 4*y[1:-1:2] + y[2::2])\n\n# Demonstrate Simpson's method with a simple example\ndef f_demo(x):\n    \"\"\"Example function: sin(x)\"\"\"\n    return np.sin(x)\n\n# Visualize Simpson's method with a few segments\nx_demo = np.linspace(0, np.pi, 7)  # 6 intervals\ny_demo = f_demo(x_demo)\n\nplt.figure(figsize=get_size(15, 8))\n# Plot the actual function\nx_fine = np.linspace(0, np.pi, 1000)\ny_fine = f_demo(x_fine)\nplt.plot(x_fine, y_fine, 'b-', label='f(x) = sin(x)')\n\n# Plot the parabolic segments\nfor i in range(0, len(x_demo)-2, 2):\n    x_segment = np.linspace(x_demo[i], x_demo[i+2], 50)\n\n    # Fit a quadratic polynomial through three points\n    x_points = x_demo[i:i+3]\n    y_points = y_demo[i:i+3]\n    coeffs = np.polyfit(x_points, y_points, 2)\n    y_fit = np.polyval(coeffs, x_segment)\n\n    plt.plot(x_segment, y_fit, 'r-', alpha=0.7)\n    plt.fill_between(x_segment, 0, y_fit, alpha=0.2, color='purple')\n\nplt.plot(x_demo, y_demo, 'go', label='Sample points')\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title(\"Simpson's Method Visualization\")\nplt.grid(True)\nplt.legend()\nplt.show()\n```\n\n\n### Convergence Analysis\n\n```{pyodide}\n# Convergence demonstration with a simple test function\nf_test = lambda x: x**4  # We can integrate x⁴ exactly\nexact_value = 1/5  # Exact integral of x⁴ from 0 to 1\n\n# Compare accuracy with different numbers of points\nN_values = np.arange(3, 101, 2)  # Odd numbers for Simpson's rule\nsimp_errors = [abs(int_simp(f_test, 0, 1, n) - exact_value) for n in N_values]\n\n# Fit a power law to error vs N\npopt, _ = curve_fit(power_law, N_values, simp_errors)\n\nplt.figure(figsize=get_size(12, 10))\nplt.loglog(N_values, simp_errors, 'o', label=\"Simpson's method error\")\nplt.loglog(N_values, power_law(N_values, *popt), '--',\n         label=f'Power law fit: error ∝ N^{popt[1]:.2f}')\nplt.xlabel('number of points [N]')\nplt.ylabel('absolute error')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nprint(f\"Simpson's Method convergence rate: approximately O(N^{popt[1]:.2f})\")\n\n```\n:::\n\n::: {.callout-note collapse=true}\n### Simpson's Rule for Numerical Integration\n\nSimpson's Rule is a method for numerical integration that approximates the definite integral of a function by using quadratic polynomials.\n\n\n1) For an integral $\\int_a^b f(x)dx$, Simpson's Rule fits a quadratic function through three points:\n\n   - $f(a)$\n   - $f(\\frac{a+b}{2})$\n   - $f(b)$\n\n2) Let's define:\n\n   - $h = \\frac{b-a}{2}$\n   - $x_0 = a$\n   - $x_1 = \\frac{a+b}{2}$\n   - $x_2 = b$\n\n3) The quadratic approximation has the form:\n   $$P(x) = Ax^2 + Bx + C$$\n\n4) This polynomial must satisfy:\n   $$f(x_0) = Ax_0^2 + Bx_0 + C$$\n   $$f(x_1) = Ax_1^2 + Bx_1 + C$$\n   $$f(x_2) = Ax_2^2 + Bx_2 + C$$\n\n5) Using Lagrange interpolation:\n   $$P(x) = f(x_0)L_0(x) + f(x_1)L_1(x) + f(x_2)L_2(x)$$\n\n   where $L_0$, $L_1$, $L_2$ are the Lagrange basis functions.\n\n#### Final Formula\n\nThe integration of this polynomial leads to Simpson's Rule:\n\n$$\\int_a^b f(x)dx \\approx \\frac{h}{3}[f(a) + 4f(\\frac{a+b}{2}) + f(b)]$$\n\n### Error Term\n\nThe error in Simpson's Rule is proportional to:\n\n$$-\\frac{h^5}{90}f^{(4)}(\\xi)$$\n\nfor some $\\xi \\in [a,b]$\n\n#### Composite Simpson's Rule\n\nFor better accuracy, we can divide the interval into $n$ subintervals (where $n$ is even):\n\n$$\\int_a^b f(x)dx \\approx \\frac{h}{3}[f(x_0) + 4\\sum_{i=1}^{n/2}f(x_{2i-1}) + 2\\sum_{i=1}^{n/2-1}f(x_{2i}) + f(x_n)]$$\n\nwhere $h = \\frac{b-a}{n}$\n\n\nThe method is particularly effective for integrating functions that can be well-approximated by quadratic polynomials over small intervals.\n:::\n\n\n### When to Use Each Method\n\nChoosing the appropriate numerical integration method for a physics problem requires consideration of several factors:\n\n| Method | Error Order | Optimal For | Limitations | Example Physics Applications |\n|--------|------------|-------------|-------------|-------------------------------|\n| **Box** | $O(N^{-1})$ | - Simple, rapid calculations<br>- Step functions<br>- Real-time processing<br>- Discontinuous functions | - Low accuracy<br>- Requires many points for decent results | - Basic data analysis<br>- Signals with sharp transitions<br>- First approximations in mechanics |\n| **Trapezoid** | $O(N^{-2})$ | - Smooth, continuous functions<br>- Moderate accuracy requirements<br>- Periodic functions | - Struggles with sharp peaks<br>- Not ideal for higher derivatives | - Electric and magnetic fields<br>- Orbital mechanics<br>- Path integrals<br>- Work/energy calculations |\n| **Simpson** | $O(N^{-4})$ | - Functions with significant curvature<br>- High precision requirements<br>- Oscillatory integrands | - More computationally intensive<br>- Requires evenly spaced points | - Quantum mechanical probabilities<br>- Wave optics<br>- Statistical mechanics<br>- Thermal physics |\n\n#### Additional Considerations\n\n- **Adaptive methods** can be more efficient when dealing with functions that have varying behavior across the integration range\n- **Improper integrals** (with infinite limits or singularities) often require specialized techniques beyond these basic methods\n- **Higher-dimensional** integration problems (common in statistical and quantum mechanics) may benefit from Monte Carlo methods rather than these quadrature rules\n\n## Error Analysis\n\nThe error behavior of numerical integration methods is crucial for understanding their applicability to physics problems:\n\n- **Box Method**: Error $\\propto$ $O(\\Delta x)$ = $O(N^{-1})$ (linear convergence)\n  - The error is proportional to the step size\n  - The dominant error term comes from the first derivative of the function\n\n- **Trapezoid Method**: Error $\\propto$ $O(\\Delta x^2)$ = $O(N^{-2})$ (quadratic convergence)\n  - The error is proportional to the square of the step size\n  - The dominant error term involves the second derivative of the function\n\n- **Simpson's Method**: Error $\\propto$ $O(\\Delta x^4)$ = $O(N^{-4})$ (fourth-order convergence)\n  - The error is proportional to the fourth power of the step size\n  - The dominant error term involves the fourth derivative of the function\n\nConsequently, if we double the number of points:\n\n- Box method: error reduced by a factor of 2\n- Trapezoid method: error reduced by a factor of 4\n- Simpson's method: error reduced by a factor of 16\n\nThe practical impact of these convergence rates is substantial. For example, to achieve an error of $10^{-6}$ for a well-behaved function:\n\n- Box method might require millions of points\n- Trapezoid method might require thousands of points\n- Simpson's method might require only hundreds of points\n\nThis explains why higher-order methods are generally preferred for physics applications requiring high precision, such as quantum mechanical calculations, gravitational wave analysis, or computational fluid dynamics.\n\n### Conclusion\n\nNumerical integration stands as a cornerstone of computational physics, bridging the gap between theoretical models and practical analysis of real-world systems. In this lecture, we've explored three fundamental methods—Box, Trapezoid, and Simpson's method—that provide different balances of simplicity, accuracy, and computational efficiency.\n\nThe key insights from our study include:\n\n1. **Method selection matters**: The choice of integration technique can dramatically impact both accuracy and computational efficiency. For typical physics applications requiring high precision, Simpson's method often provides the optimal balance of accuracy and computation cost.\n\n2. **Error scaling**: Understanding how errors scale with the number of sampling points is crucial for reliable scientific computation. The higher-order convergence of Simpson's method ($O(N^{-4})$) makes it particularly valuable for precision-critical applications in physics.\n\n3. **Physical context**: The nature of the underlying physical system should guide your choice of numerical method. Smoothly varying functions benefit from higher-order methods, while functions with discontinuities may require adaptive or specialized approaches.\n\n4. **Verification**: Always verify numerical results against analytical solutions when possible, or compare results from different numerical methods with increasing resolution to establish confidence in your calculations.\n\nAs you progress in your physics education, these numerical integration techniques will become essential tools in your computational toolkit, enabling you to tackle increasingly complex physical systems from quantum mechanics to astrophysics, fluid dynamics, and beyond.\n\nIn advanced courses, you'll explore additional techniques such as Gaussian quadrature, Romberg integration, and specialized methods for oscillatory, singular, or multi-dimensional integrals—each designed to address specific challenges encountered in modern physics.\n\nRemember that numerical integration is not merely a computational technique but a powerful approach to understanding physical systems that resist analytical treatment, making it an indispensable skill for the modern physicist.\n\n\n::: {.callout-note collapse=true}\n## Advanced Topics in Numerical Integration\n\n### Adaptive Integration Methods\n\nThe methods we've discussed so far use equal spacing between sampling points. However, most real-world physics problems involve functions that vary dramatically across the integration range. Adaptive methods adjust the point distribution to concentrate more points where the function changes rapidly.\n\n```{pyodide}\n# Simple demonstration of adaptive integration concept\ndef adaptive_demo(f, a, b, tol=1e-5, max_depth=10):\n    \"\"\"Simple demonstration of adaptive integration concept\"\"\"\n    def recursive_integrate(a, b, depth=0):\n        # Compute midpoint\n        c = (a + b) / 2\n\n        # Estimate integral using Simpson's rule on entire interval\n        I_whole = (b-a)/6 * (f(a) + 4*f(c) + f(b))\n\n        # Estimate integral using Simpson's rule on each half\n        mid1 = (a + c) / 2\n        mid2 = (c + b) / 2\n        I_left = (c-a)/6 * (f(a) + 4*f(mid1) + f(c))\n        I_right = (b-c)/6 * (f(c) + 4*f(mid2) + f(b))\n        I_parts = I_left + I_right\n\n        # Check error\n        error = abs(I_whole - I_parts)\n\n        # If error is small enough or max depth reached, return result\n        if error < tol*(b-a) or depth >= max_depth:\n            return I_parts, [(a, c, b, error)]\n\n        # Otherwise, recursively integrate each half\n        I_left_result, left_regions = recursive_integrate(a, c, depth+1)\n        I_right_result, right_regions = recursive_integrate(c, b, depth+1)\n\n        return I_left_result + I_right_result, left_regions + right_regions\n\n    integral, regions = recursive_integrate(a, b)\n    return integral, regions\n\n# Define a challenging function with a sharp peak\ndef challenging_func(x):\n    \"\"\"Function with a sharp peak at x=0.7\"\"\"\n    return 1 / (0.01 + (x - 0.7)**2)\n\n# Calculate integral using adaptive and non-adaptive methods\na, b = 0, 1\nn_points = 101  # Use a fixed number of points for non-adaptive methods\n\n# Calculate using non-adaptive methods\nbox_result = int_box(challenging_func, a, b, n_points)\ntrap_result = int_trap(challenging_func, a, b, n_points)\nsimp_result = int_simp(challenging_func, a, b, n_points)\n\n# Calculate using adaptive method\nadaptive_result, regions = adaptive_demo(challenging_func, a, b)\n\n# Calculate a reference solution using a very high number of points\nreference = int_simp(challenging_func, a, b, 10001)\n\n# Visualize the function and integration points\nx_fine = np.linspace(a, b, 1000)\ny_fine = [challenging_func(x) for x in x_fine]\n\nplt.figure(figsize=get_size(15, 10))\n\n# Plot the function\nplt.plot(x_fine, y_fine, 'k-', label='f(x)')\n\n# Plot the adaptive integration regions\nfor region in regions:\n    a_r, m_r, b_r, error = region\n    plt.plot([a_r, m_r, b_r], [challenging_func(a_r), challenging_func(m_r), challenging_func(b_r)],\n             'ro-', alpha=0.5)\n\nplt.xlabel('x')\nplt.ylabel('f(x)')\n\n\n# Adjust y-axis to show the function's behavior more clearly\nplt.ylim(0, 40)\n\nplt.legend()\nplt.show()\n\n# Show results\nprint(\"Results for integrating a function with a sharp peak:\")\nprint(f\"Box Method (n={n_points}): {box_result:.8f}, Error: {abs(box_result-reference):.8f}\")\nprint(f\"Trapezoid Method (n={n_points}): {trap_result:.8f}, Error: {abs(trap_result-reference):.8f}\")\nprint(f\"Simpson's Method (n={n_points}): {simp_result:.8f}, Error: {abs(simp_result-reference):.8f}\")\nprint(f\"Adaptive Method: {adaptive_result:.8f}, Error: {abs(adaptive_result-reference):.8f}\")\nprint(f\"Reference value: {reference:.8f}\")\nprint(f\"Number of adaptive regions: {len(regions)}\")\n```\n\n### Multi-dimensional Integration\n\nMany physics problems require integration over multiple dimensions, such as calculating mass moments of inertia, electric fields from volume charge distributions, or statistical mechanics partition functions.\n\nFor 2D integration, we can extend our 1D methods using the concept of iterated integrals:\n\n\\begin{equation}\n\\int_{a}^{b}\\int_{c}^{d} f(x,y) dy dx \\approx \\sum_{i=1}^{N_x} \\sum_{j=1}^{N_y} w_i w_j f(x_i, y_j)\n\\end{equation}\n\nWhere $w_i$ and $w_j$ are the weights for the respective 1D methods.\n\n```{pyodide}\ndef int_2d_trap(f, x_range, y_range, nx, ny):\n    \"\"\"2D integration using the Trapezoid method\"\"\"\n    x = np.linspace(x_range[0], x_range[1], nx)\n    y = np.linspace(y_range[0], y_range[1], ny)\n    dx = (x_range[1] - x_range[0]) / (nx - 1)\n    dy = (y_range[1] - y_range[0]) / (ny - 1)\n\n    result = 0\n    for i in range(nx-1):\n        for j in range(ny-1):\n            # Average of function values at the four corners of each cell\n            f_values = [\n                f(x[i], y[j]),\n                f(x[i+1], y[j]),\n                f(x[i], y[j+1]),\n                f(x[i+1], y[j+1])\n            ]\n            result += sum(f_values) / 4 * dx * dy\n\n    return result\n\n# Example: Electric potential from a square charge distribution\ndef potential_2d(x, y, z=1):\n    \"\"\"Electric potential at (x,y,z) from a square charge distribution in the x-y plane\"\"\"\n    # Avoid division by zero\n    denominator = (x**2 + y**2 + z**2)**0.5\n    if denominator < 1e-10:\n        return 0\n    return 1 / denominator\n\n# Calculate the electric potential at a point above a charged square\nz = 1.0  # height above the plane\npotential = int_2d_trap(lambda x, y: potential_2d(x, y, z), [-1, 1], [-1, 1], 51, 51)\n\n# Visualize the potential in the plane above the charge\nx_vals = np.linspace(-2, 2, 50)\ny_vals = np.linspace(-2, 2, 50)\nX, Y = np.meshgrid(x_vals, y_vals)\nZ = np.zeros_like(X)\n\nfor i in range(len(x_vals)):\n    for j in range(len(y_vals)):\n        Z[j, i] = potential_2d(X[j, i], Y[j, i], z)\n\nplt.figure(figsize=get_size(15, 10))\n\n# Plot the potential as a contour\ncontour = plt.contourf(X, Y, Z, 50, cmap='viridis')\nplt.colorbar(label='Electric Potential')\n\n# Mark the square charge distribution\nplt.plot([-1, 1, 1, -1, -1], [-1, -1, 1, 1, -1], 'r-', linewidth=2)\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.axis('equal')\n\nplt.show()\n\nprint(f\"Electric potential at point (0,0,{z}): {potential:.6f}\")\nprint(f\"Analytical value at center: {np.log(1 + np.sqrt(2)):.6f}\")\n```\n\n### Monte Carlo Integration\n\nFor higher-dimensional integrals and complex domains, Monte Carlo methods become increasingly efficient. These methods use random sampling to approximate integrals and are particularly valuable in quantum and statistical physics.\n\n```{pyodide}\ndef monte_carlo_integrate(f, ranges, n_samples):\n    \"\"\"Monte Carlo integration in arbitrary dimensions\"\"\"\n    # Generate random samples within the integration domain\n    dim = len(ranges)\n    samples = np.random.uniform(\n        low=[r[0] for r in ranges],\n        high=[r[1] for r in ranges],\n        size=(n_samples, dim)\n    )\n\n    # Evaluate function at sample points\n    f_values = np.array([f(*sample) for sample in samples])\n\n    # Calculate volume of integration domain\n    volume = np.prod([r[1] - r[0] for r in ranges])\n\n    # Estimate integral and error\n    integral = volume * np.mean(f_values)\n    error = volume * np.std(f_values) / np.sqrt(n_samples)\n\n    return integral, error\n\n# Example: Calculate the volume of a n-dimensional hypersphere\ndef sphere_indicator(x, y, z):\n    \"\"\"Return 1 if point is inside unit sphere, 0 otherwise\"\"\"\n    return 1 if x**2 + y**2 + z**2 <= 1 else 0\n\n# Calculate the volume of a 3D sphere using Monte Carlo\nn_samples = 100000\nranges = [[-1, 1], [-1, 1], [-1, 1]]  # Cube containing the sphere\nvolume, error = monte_carlo_integrate(sphere_indicator, ranges, n_samples)\n\n# The exact volume of a unit sphere in 3D is (4/3)π\nexact_volume = 4/3 * np.pi\n\n# Visualize the convergence\nsample_sizes = np.logspace(2, 5, 20, dtype=int)\nvolumes = []\nerrors = []\n\nfor n in sample_sizes:\n    v, e = monte_carlo_integrate(sphere_indicator, ranges, n)\n    volumes.append(v)\n    errors.append(e)\n\nplt.figure(figsize=get_size(15, 10))\nplt.semilogx(sample_sizes, volumes, 'o-', label='Monte Carlo estimate')\nplt.fill_between(\n    sample_sizes,\n    [v - e for v, e in zip(volumes, errors)],\n    [v + e for v, e in zip(volumes, errors)],\n    alpha=0.3\n)\nplt.axhline(exact_volume, color='r', linestyle='--', label='Exact value')\nplt.xlabel('Number of samples')\nplt.ylabel('Volume of unit sphere')\nplt.legend()\nplt.show()\n\nprint(f\"Volume of unit sphere (Monte Carlo with {n_samples} samples): {volume:.6f} ± {error:.6f}\")\nprint(f\"Exact volume of unit sphere: {exact_volume:.6f}\")\nprint(f\"Relative error: {abs(volume - exact_volume)/exact_volume*100:.4f}%\")\n```\n\n### Application to Real Physics Problems\n\nLet's examine two common scenarios in physics that benefit from numerical integration:\n\n1. **Non-uniform Magnetic Field**: When a charged particle moves through a non-uniform magnetic field, the work done can be calculated as:\n\n   $$W = q\\int_{\\vec{r}_1}^{\\vec{r}_2} \\vec{v} \\times \\vec{B}(\\vec{r}) \\cdot d\\vec{r}$$\n\n2. **Quantum Tunneling**: The tunneling probability through a potential barrier is given by:\n\n   $$T \\approx \\exp\\left(-\\frac{2}{\\hbar}\\int_{x_1}^{x_2} \\sqrt{2m(V(x) - E)}\\, dx\\right)$$\n\nIn both cases, the integrals frequently cannot be solved analytically due to the complex spatial dependence of the fields or potentials, making numerical integration indispensable for modern physics.\n:::\n\n",
    "supporting": [
      "2-integration_files"
    ],
    "filters": [],
    "includes": {}
  }
}